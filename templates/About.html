<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>‚ÑπÔ∏è About ‚Äì InstruNet AI</title>
  <link rel="stylesheet" href="/static/style.css">
</head>
<body>

<!-- ================= TOP NAV BAR ================= -->
<div class="top-nav">
  <div class="nav-left">
    üéµ <b>InstruNet AI</b>
  </div>
  <div class="nav-links">
    <a href="/home">Home</a>
    <a href="/analysis">Analysis</a>
    <a href="/results">Results</a>
    <a href="/history">History</a>
    <a href="/about">About</a>
  </div>
</div>
<!-- ================= END TOP NAV ================= -->

<div class="app">

  <!-- HEADER -->
  <div class="header">
    <h1>‚ÑπÔ∏è About InstruNet AI</h1>
    <p>Model, dataset, and system overview</p>
  </div>

  <!-- GRID -->
  <div class="grid">

    <!-- LEFT: PROJECT OVERVIEW -->
    <div class="card left">
      <div class="panel">
        <h3 class="panel-title">Project Overview</h3>

        <p style="font-size:14px; line-height:1.6; color:#cbd5f5;">
          <b>InstruNet AI</b> is a deep learning‚Äìbased web application designed
          to automatically recognize musical instruments from audio recordings.
          The system converts raw audio signals into
          <b>Mel Spectrograms</b>, which are then processed by a convolutional
          neural network for classification.
        </p>

        <p style="margin-top:10px;font-size:14px;line-height:1.6;color:#cbd5f5;">
          The application provides real-time instrument detection, probability
          scores, temporal timelines, and downloadable analysis reports.
        </p>
      </div>
    </div>

    <!-- CENTER: MODEL DETAILS -->
    <div class="card center">
      <div class="panel analysis-box">
        <h3 class="panel-title">Model Architecture</h3>

        <ul class="detected">
          <li>‚úî Architecture: <b>ResNet-18</b></li>
          <li>‚úî Framework: <b>PyTorch</b></li>
          <li>‚úî Input Representation: <b>Mel Spectrogram</b></li>
          <li>‚úî Input Size: <b>128 √ó 128 ‚Üí resized to 224 √ó 224</b></li>
          <li>‚úî Channels: <b>3-channel (RGB-style)</b></li>
          <li>‚úî Output Classes: <b>11 musical instruments</b></li>
        </ul>

        <p style="margin-top:10px;font-size:14px;color:#cbd5f5;">
          The ResNet-18 model was fine-tuned by modifying the final fully
          connected layer. Transfer learning helps capture meaningful
          time‚Äìfrequency patterns from spectrogram images.
        </p>
      </div>
    </div>

    <!-- RIGHT: DATASET + TECH -->
    <div class="card right">
      <div class="panel">
        <h3 class="panel-title">Dataset</h3>

        <ul class="detected">
          <li>‚úî Dataset: <b>IRMAS</b></li>
          <li>‚úî Audio Type: Single-instrument recordings</li>
          <li>‚úî Sample Rate: 22,050 Hz</li>
          <li>‚úî Audio Formats: WAV / MP3 / FLAC</li>
          <li>‚úî Total Classes: 11 instruments</li>
        </ul>
      </div>

      <div class="panel">
        <h3 class="panel-title">Technologies Used</h3>

        <ul class="detected">
          <li>‚úî Python & Flask</li>
          <li>‚úî PyTorch & Torchvision</li>
          <li>‚úî Librosa (audio processing)</li>
          <li>‚úî HTML, CSS, JavaScript</li>
          <li>‚úî ReportLab (PDF export)</li>
        </ul>
      </div>
    </div>

  </div>



</div>

</body>
</html>
